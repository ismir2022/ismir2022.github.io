import React from "react";

const Latebreaking = () => {
  return (
    <div className="space-y-10">
      <div>
        <h1 className="text-[#d83616] font-bold md:text-3xl text-2xl mt-5">
          Late-breaking/Demo (LBD)
        </h1>
      </div>

      <div className="space-y-3">
        <p className="text-lg">
          The Late-breaking/Demo (LBD) session is a forum for sharing prototype systems, initial concepts, and early results which may have not yet fully matured but are of interest to the Music-IR community. 
          It is also a great entry point for people who are new to ISMIR to showcase their preliminary work and receive early feedback from fellow researchers. 
          Attendees of the LBD can interact with demos or discuss their thoughts on the latest developments in the field.
        </p>
      </div>
      
        <p className="text-xl text-[#d83616] font-bold">Hybrid Conference</p>
        <p className="text-lg">
          Similar to the main paper track, this year’s LBD will be held in a hybrid format, i.e., physical and remote. 
          There will be two back-to-back sessions:
            <ol>
            <li>Physical session: Dec 8, 2022 (Thu), 3.30 pm - 5.30 pm</li>
            <li>Virtual session: Dec 8, 2022 (Thu), 5.30 pm - 7.00 pm</li>
            </ol>
        </p>

        <p className="text-xl text-[#d83616] font-bold">Instructions to participants/attendees</p>
        <p className="text-lg">
          Each LBD extended abstract will have a dedicated slack channel on the virtual platform and will have the abstract
          and poster / video on MiniConf.Both in -person and remote attendees can ask asynchronous questions to remote or
          in -person presenters via the slack channel.
            <ol>
            <li>Physical session: The LBD posters by in-person attendees will be presented during this session at the venue.
                Virtual presenters can choose to remain online to interact with any interested participants.</li>
            <li>Remote session: Remote presenters can use the huddle feature on each LBD extended abstract slack channel to
                present their LBD posters on a video call. (Huddle supports up to 50 simultaneous participants).</li>
            </ol >
        </p >
  
        <p className="text-xl text-[#d83616] font-bold">Open Session</p>
        <p className="text-lg">
          This year’s local LBD session is also an open session for students and independent researchers of the local community. 
          The session will enable participants to attend the late-breaking/demo session of the conference and interact with students, experts and senior members of the ISMIR research community. 
          This open session is a free registration event.
        </p>
        
        <p className="text-lg">
          Accepted LBD submissions are below. More submissions to be added soon!
        </p>

      <dl>
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Hit Song Prediction for Indian Popular Music</strong></dt>
            <dd>Shreya Kale, Makarand Velankar, Rameshwari Joshi, Vaishnavi Ingole, Aparna Dhaygude</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Audio Augmentations for Semi-Supervised Learning with FixMatch</strong></dt>
            <dd>Sascha Grollmisch, Estefanía Cano, Jakob Abeßer</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>libf0: A Python Library for Fundamental Frequency Estimation</strong></dt>
            <dd>Sebastian Rosenzweig, Simon J Schwär, Meinard Müller</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Genre Classification and Analysis of Marathi Songs</strong></dt>
            <dd>Shreyas M Nadkarni, Preeti Rao</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Towards Singer-independent Raga Classification from Audiovisual Recordings</strong></dt>
            <dd>Adbhut V Bhardwaj, Sujoy Roychowdhury, Preeti Rao</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>EGFxSet: Electric Guitar Tones Processed Through Real Effects of Distortion, Modulation, Delay and
                    Reverb</strong></dt>
            <dd>Hegel Emmanuel Pedroza, Gerardo Meza, Iran R Roman</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Generating Melodies with Controllable Similarity and Length in ABC Notation</strong></dt>
            <dd>Shangda Wu, Yuanliang Dong, Maosong Sun</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Improving tokenization expressiveness with pitch intervals</strong></dt>
            <dd>Louis Bigo, Mikaela Keller</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Visualizing Chord Recognition Performance</strong></dt>
            <dd>Christopher Liscio, Dan Brown</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Towards modeling alternating patterns through inter-notes relations</strong></dt>
            <dd>Perrine Vantalon, Mathieu Giraud, Richard Groult, Thierry Lecroq</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Exploring Popularity Bias in Music Steaming Services</strong></dt>
            <dd>Douglas Turnbull, Vera Crabtree, Sean McQuillan</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Decoding and Visualising Intended Emotion in an Expressive Piano Performance</strong></dt>
            <dd>Shreyan Chowdhury, Gerhard Widmer</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>CCVS: A dataset for concert videography research</strong></dt>
            <dd>Hsin-Min Chou, Ting-Wei Lin, Jen-Chun Lin, Ching Te Chiu, Li Su</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Augmented Reality Visualization for Musical Instrument Learning</strong></dt>
            <dd>Frank Heyen, Michael Sedlmair</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>AudioLoader: a hassle-free Pytorch audio dataset loader</strong></dt>
            <dd>Kin Wai Cheuk, Kwan Yee Heung, Dorien Herremans</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>A Web-Based MIDI Controller for Music Live Coding</strong></dt>
            <dd>Frank Heyen, Michael Sedlmair</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Gamaka Synthesis for Kalpitha Swaras in Carnatic music</strong></dt>
            <dd>Raghavasimhan Sankaranarayanan, Gil Weinberg</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>SSM-NET: Feature Learning for Music Structure Analysis Using a Self-similarity-matrix Based
                    Loss</strong></dt>
            <dd>Geoffroy Peeters, Florian Angulo</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Differentiating the Pitch Bend Function Between the Sitar as a Real and Virtual Instrument</strong></dt>
            <dd>Suhit Chiruthapudi</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Improvisation of tabla the indian percussion using fibre</strong></dt>
            <dd>Retnasree Iyer</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>On the Typicality of Music</strong></dt>
            <dd>Mathais Rose Bjare, Stefan Lattner</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Towards a machine-learning approach to analyse the emotional impact of source localization in
                    music</strong></dt>
            <dd>Eleonora De Filippi, Timothy Schmele, Arijit Nandi</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>A CHORD PROGRESSION LIBRARY FOR MEASURING EMOTIONS BY BCIs</strong></dt>
            <dd>Raffaella Folgieri, Enrico Daga, Claudio Lucchiari, Paul Arnold</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Rapidly Predicting Music Artistic Expression Preference From Heart Rate and Respiration Rate</strong>
            </dt>
            <dd>Shu Sakamoto, Vincent Cheung, Shinichi Furuya</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>MuSFA: Improving Music Structural Function Analysis with Partially Labeled Data</strong></dt>
            <dd>Ju-Chiang Wang, Jordan B. L. Smith, Yun-Ning Hung</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Audio Metaphor 2.0: An Improved System for Automatic Sound Design</strong></dt>
            <dd>Renaud Bougueng Tchemeube, Joshua Kranabetter, Craig Carpenter, Philippe Pasquier, Miles Thorogood</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Calliope: An Online Interface for Generative Music Co-Creation</strong></dt>
            <dd>Renaud Bougueng Tchemeube, Jeffrey Ens, Cale Plut, Philippe Pasquier</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Western Music Notation for Java: A library for music notation on the JVM</strong></dt>
            <dd>Otso Björklund</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>A Multimodal Approach to Acoustic Guitar Strumming Action Transcription</strong></dt>
            <dd>Sebastian Murgul, Michael Heizmann</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Midi-Draw: Sketching To Control Melody Generation</strong></dt>
            <dd>Tashi Namgyal</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>AI-driven, mobile-first web UI for controllable expressive piano performance composition</strong></dt>
            <dd>Théis Bazin, Gaëtan Hadjeres, Mikhail Malt</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Beatoven.ai: AI-powered music creation</strong></dt>
            <dd>António Ramires, Siddharth Bhardwaj</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Facets: A Tool For Management And Navigation Of Symbolic Music Collections</strong></dt>
            <dd>Tiange Zhu, Raphael Fournier-S'niehotta</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Melody Slot Machine HD</strong></dt>
            <dd>Masatoshi Hamanaka</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Assistive alignment of in-the-wild sheet music and performances</strong></dt>
            <dd>Michael Feffer, Chris Donahue, Zachary Lipton</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Note level MIDI velocity estimation for piano performance</strong></dt>
            <dd>Hyon Kim, Marius Miron, Xavier Serra</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Essentia API: a web API for music audio analysis</strong></dt>
            <dd>Albin Andrew Correya, Dmitry Bogdanov, Pablo Alonso-Jiménez, Xavier Serra</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Differentiable WORLD Synthesizer-Based Neural Vocoder With Application To End-To-End Audio Style
                    Transfer</strong></dt>
            <dd>Shahan Nercessian</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Schmubert: A Symbolic Creative Harmonic Music Unmasking Bidirectional Encoder Representation
                    Transformer</strong></dt>
            <dd>Matthias Plasser, Silvan Peter</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Song Describer: a Platform for Collecting Textual Descriptions of Music Recordings</strong></dt>
            <dd>Ilaria Manco, Benno Weck, Philip Tovstogan, Minz Won, Dmitry Bogdanov</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>A Framework for Instrument Recognition Using Conditional Generative Adversarial Networks</strong></dt>
            <dd>Charis Cochran, Youngmoo Kim</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Differentiable Acoustic Guitar Synthesis from Tablature</strong></dt>
            <dd>Andrew F Wiggins, Youngmoo Kim</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>A New Pianoroll With Relative Pitch Approach</strong></dt>
            <dd>Seonghyeon Go</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Unsupervised Domain Adaptation For Sound Event Detection In Music Applications</strong></dt>
            <dd>Arkaprava Biswas, Akshay Raina, Vipul Arora</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation
                    Learning</strong></dt>
            <dd>Yizhi Li, Ruibin Yuan, Ge Zhang, Yinghao MA, Chenghua Lin, Xingran Chen, Anton Ragni, Hanzhi Yin, Zhijie Hu,
                Haoyu He, Emmanouil Benetos, Norbert Gyenge,Ruibo Liu, Jie Fu</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>CogXAI ANNalyzer: Cognitive Neuroscience Inspired Techniques for eXplainable AI</strong></dt>
            <dd>Maral Ebrahimzadeh, Valerie Krug, Sebastian Stober</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>A Family of Libraries for Working With Pitches and Intervals</strong></dt>
            <dd>Christoph Finkensiep, Robert Lieck, Martin A Rohrmeier</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Audio Latent Space Cartography</strong></dt>
            <dd>Nicolas Jonason, Bob Sturm</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>DiscStitch: towards audio-to-audio alignment with robustness to playback speed variabilities</strong>
            </dt>
            <dd>Joren Six</dd>
        </div>
        
        <div style={{paddingBottom:"10px"}}>
            <dt><strong>Neural Waveform Synthesis on a Low-Resource Embedded Device</strong></dt>
            <dd>Alexander Tipper</dd>
        </div>
      </dl>
        
    </div>
  );
};

export default Latebreaking;
